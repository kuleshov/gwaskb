{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phenotype/SNP relation extraction from tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import cPickle\n",
    "\n",
    "# import snorkel and gwasdb\n",
    "sys.path.append('../snorkel')\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../src/crawler')\n",
    "\n",
    "# set up paths\n",
    "abstract_dir = '../data/db/papers'\n",
    "\n",
    "# set up matplotlib\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (12,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import XMLDocParser\n",
    "from extractor.parser import UnicodeXMLTableDocParser\n",
    "\n",
    "xml_parser = UnicodeXMLTableDocParser(\n",
    "    path=abstract_dir,\n",
    "    doc='./*',\n",
    "    text='.//table',\n",
    "    id='.//article-id[@pub-id-type=\"pmid\"]/text()',\n",
    "    keep_xml_tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.9 s, sys: 3.28 s, total: 57.2 s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.parser import HTMLParser\n",
    "from extractor.parser import UnicodeTableParser\n",
    "from snorkel.parser import CorpusParser\n",
    "import cPickle\n",
    "\n",
    "table_parser = UnicodeTableParser()\n",
    "html_parser = HTMLParser(path='../data/db/papers/')\n",
    "\n",
    "corpus_name = 'gwas-table-corpus.pkl'\n",
    "\n",
    "try:\n",
    "    with open(corpus_name,\"r\") as pkl:\n",
    "        corpus = cPickle.load(pkl)\n",
    "except:\n",
    "    cp = CorpusParser(xml_parser, table_parser, max_docs=15)\n",
    "    %time corpus = cp.parse_corpus(name='GWAS Corpus')\n",
    "    # pickling currently doesn't work...\n",
    "#     with open(corpus_name,\"w\") as pkl:\n",
    "#         corpus = cPickle.dump(corpus, pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RSid Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.matchers import DictionaryMatch, RegexMatchSpan, Union\n",
    "from snorkel.candidates import EntityExtractor\n",
    "from snorkel.candidates import TableNgrams\n",
    "\n",
    "from db.kb import KnowledgeBase\n",
    "\n",
    "# Define a candidate space\n",
    "ngrams = TableNgrams(n_max=1)\n",
    "\n",
    "# Get a list of all the RSids we know\n",
    "kb = KnowledgeBase()\n",
    "rs_ids = kb.get_rsid_candidates()\n",
    "\n",
    "# Define matchers\n",
    "dict_rsid_matcher = DictionaryMatch(d=rs_ids, longest_match_only=False)\n",
    "regx_rsid_matcher = RegexMatchSpan(rgx=r'rs\\d+')\n",
    "rsid_matcher = Union(dict_rsid_matcher, regx_rsid_matcher)\n",
    "\n",
    "rsid_extractor = EntityExtractor(ngrams, rsid_matcher)\n",
    "# %time rs_candidates = rsid_extractor.extract(corpus.get_tables(), name='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span(\"rs2076756\", context=None, chars=[0,8], words=[0,0])\n",
      "Span(\"rs1992662\", context=None, chars=[0,8], words=[0,0])\n",
      "Span(\"rs1992660\", context=None, chars=[0,8], words=[0,0])\n",
      "Span(\"rs1793004\", context=None, chars=[0,8], words=[0,0])\n",
      "Span(\"rs10521209\", context=None, chars=[0,9], words=[0,0])\n",
      "Span(\"rs2631372\", context=None, chars=[0,8], words=[0,0])\n",
      "Span(\"rs2925757\", context=None, chars=[0,8], words=[0,0])\n",
      "Span(\"rs6947579\", context=None, chars=[0,8], words=[0,0])\n",
      "Span(\"rs1553575\", context=None, chars=[0,8], words=[0,0])\n",
      "Span(\"rs10484545\", context=None, chars=[0,9], words=[0,0])\n",
      "1577 candidates extracted\n",
      "Phrase('17684544', 1, 20, 0, u'rs2076756')\n",
      "Cell('17684544', 1, 20, u'rs2076756')\n"
     ]
    }
   ],
   "source": [
    "for cand in rs_candidates[:10]: \n",
    "    print cand\n",
    "print \"%s candidates extracted\" % len(rs_candidates)\n",
    "print rs_candidates[0].context\n",
    "print rs_candidates[0].context.cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of gold annotations\t= 178\n",
      "# of candidates\t\t= 1371\n",
      "Candidate recall\t= 0.978\n",
      "Candidate precision\t= 0.127\n"
     ]
    }
   ],
   "source": [
    "from extractor.util import gold_rsid_stats, gold_rsid_precision\n",
    "\n",
    "gold_set = frozenset( [ (doc.name, rs_id) for doc in corpus.documents for rs_id in kb.rsids_by_pmid(int(doc.name)) ] )\n",
    "gold_set_rsids = [rs_id for doc_id, rs_id in gold_set]\n",
    "\n",
    "gold_rsid_stats(rs_candidates, gold_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting: some SNPs seem to be never mentioned (e.g. rs12122100) while others (rs727153) appear only in the text.\n",
    "Sometimes, it's not picked up for a different, strange reason: see rs13314993."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1',\n",
       " u'16',\n",
       " u'49,314,382',\n",
       " u'CARD15, intron',\n",
       " u'0.26',\n",
       " u'0.43',\n",
       " u'1.93E-13',\n",
       " u'2.04E-12',\n",
       " u'2.1 (1.58-2.80)',\n",
       " u'0.27',\n",
       " u'0.41',\n",
       " u'6.80E-20',\n",
       " u'1.39E-21',\n",
       " u'1.71 (1.42-2.05)',\n",
       " u'5.90E-08']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cells = rs_candidates[0].context.cell.aligned_cells('row')\n",
    "[cell.text for cell in cells]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.9 s, sys: 254 ms, total: 21.2 s\n",
      "Wall time: 21.1 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.matchers import DictionaryMatch, Union, CellNameMatcher, CellDictNameMatcher\n",
    "from snorkel.candidates import EntityExtractor\n",
    "from snorkel.candidates import TableNgrams, CellSpace\n",
    "\n",
    "# Define a candidate space\n",
    "ngrams = TableNgrams(n_max=9)\n",
    "cells = CellSpace()\n",
    "\n",
    "# Create a list of possible words that could denote phenotypes\n",
    "phen_words = ['trait', 'phenotype']\n",
    "\n",
    "# Define matchers\n",
    "# dict_row_matcher = DictionaryMatch(d=phen_words, longest_match_only=False, stemmer='porter')\n",
    "# cell_row_matcher = CellNameMatcher(row_matcher=dict_row_matcher, cand_space=ngrams)\n",
    "# dict_col_matcher = DictionaryMatch(d=phen_words, longest_match_only=False, stemmer='porter')\n",
    "# cell_col_matcher = CellNameMatcher(col_matcher=dict_col_matcher, cand_space=ngrams)\n",
    "# phen_matcher = Union(cell_row_matcher, cell_col_matcher)\n",
    "# phen_matcher = CellNameMatcher(col_matcher=dict_col_matcher, cand_space=ngrams)\n",
    "phen_matcher = CellDictNameMatcher(axis='col', d=phen_words, n_max=3, ignore_case=True)\n",
    "\n",
    "phen_extractor = EntityExtractor(cells, phen_matcher)\n",
    "%time phen_candidates = phen_extractor.extract(corpus.get_tables(), name='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1851 candidates extracted\n",
      "17903292 Table('17903292', 0) Cell('17903292', 0, 10, u'Serum Creatinine')\n",
      "Span(\"Serum Creatinine\", context=None, chars=[0,15], words=[0,1])\n",
      "17903292 Table('17903292', 0) Cell('17903292', 0, 15, u'Change in serum creatinine')\n",
      "Span(\"Change in serum creatinine\", context=None, chars=[0,25], words=[0,3])\n",
      "17903292 Table('17903292', 0) Cell('17903292', 0, 20, u'Glomerular Filtration Rate (GFR)')\n",
      "Span(\"Glomerular Filtration Rate (GFR)\", context=None, chars=[0,35], words=[0,5])\n",
      "17903292 Table('17903292', 0) Cell('17903292', 0, 25, u'Chronic Kidney Disease')\n",
      "Span(\"Chronic Kidney Disease\", context=None, chars=[0,21], words=[0,2])\n",
      "17903292 Table('17903292', 0) Cell('17903292', 0, 30, u'Cystatin C')\n",
      "Span(\"Cystatin C\", context=None, chars=[0,9], words=[0,1])\n",
      "17903292 Table('17903292', 0) Cell('17903292', 0, 35, u'Uric acid')\n",
      "Span(\"Uric acid\", context=None, chars=[0,8], words=[0,1])\n",
      "17903292 Table('17903292', 0) Cell('17903292', 0, 40, u'Urinary Albumin Excretion')\n",
      "Span(\"Urinary Albumin Excretion\", context=None, chars=[0,24], words=[0,2])\n",
      "17903292 Table('17903292', 0) Cell('17903292', 0, 45, u'Urinary Albumin Excretion \\u2265 30 mg/g; Hypertension-enriched sample')\n",
      "Span(\"Urinary Albumin Excretion â‰¥ 30 mg/g; Hypertension-enriched sample\", context=None, chars=[0,64], words=[0,8])\n",
      "17903292 Table('17903292', 0) Cell('17903292', 0, 50, u'Serum Calcium')\n",
      "Span(\"Serum Calcium\", context=None, chars=[0,12], words=[0,1])\n",
      "17903292 Table('17903292', 0) Cell('17903292', 0, 55, u'Serum Phosphorus')\n",
      "Span(\"Serum Phosphorus\", context=None, chars=[0,15], words=[0,1])\n",
      "\n",
      "Phrase('17903292', 0, 10, 0, u'Serum Creatinine')\n",
      "17903292 Table('17903292', 0)\n",
      "Cell('17903292', 0, 10, u'Serum Creatinine')\n"
     ]
    }
   ],
   "source": [
    "print \"%s candidates extracted\" % len(phen_candidates)\n",
    "for cand in phen_candidates[0:10]: \n",
    "    print cand.context.document.name, cand.context.table, cand.context.cell\n",
    "    print unicode(cand)\n",
    "#     print [span for span in cand.row_ngrams()]\n",
    "#     print [span for span in cand.col_ngrams()]\n",
    "#     print\n",
    "print\n",
    "print phen_candidates[0].context\n",
    "print phen_candidates[0].context.document.name, phen_candidates[0].context.table\n",
    "print phen_candidates[0].context.cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import AlignedTableRelationExtractor\n",
    "relation_extractor = AlignedTableRelationExtractor(rsid_extractor, phen_extractor, axis='row', induced=True)\n",
    "tables = corpus.get_tables()\n",
    "\n",
    "# create smaller subsets for evaluation/debugging\n",
    "easy_tables = [tables[8]]\n",
    "# hard_tables = [t for t in tables if t.document.name=='17658951']\n",
    "hard_doc = [d for d in corpus.documents if d.name == '17903293'][0]\n",
    "hard_tables = [hard_doc.tables[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time candidates = relation_extractor.extract(tables, name='all')\n",
    "print \"%s relations extracted, e.g.\" % len(candidates)\n",
    "for cand in candidates[:40]: \n",
    "    print cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fun_c = [candidate for candidate in candidates if candidate.context.document.name != '17658951']\n",
    "for c in fun_c[:10]:\n",
    "    print fun_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we remove nested candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load existing candidates into a dict\n",
    "span_dict = { str(span_pair.span1.context) : list() for span_pair in candidates }\n",
    "for span_pair in candidates:\n",
    "    span = span_pair.span1\n",
    "    span_dict[str(span.context)].append( (span.char_start, span.char_end) )\n",
    "\n",
    "def nested(ivl1, ivl2):\n",
    "    if ivl1 != ivl2 and ivl2[0] <= ivl1[0] <= ivl1[1] <= ivl2[1]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "new_candidates = list()\n",
    "for span_pair in candidates:\n",
    "    span = span_pair.span1\n",
    "    span_ivl = span.char_start, span.char_end\n",
    "    span_name = str(span.context)\n",
    "    if all([not nested(span_ivl, other_ivl) for other_ivl in span_dict[span_name]]):\n",
    "        new_candidates.append(span_pair)\n",
    "        \n",
    "print len(candidates) - len(new_candidates), 'candidates dropped, now we have', len(new_candidates)\n",
    "# phen_c = new_phen_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rs2831617 5 1 2\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Span\n",
    "fun_tables = [t for t in tables if t.document.name=='17658951']\n",
    "fun_doc = [d for d in corpus.documents if d.name == '17903293'][0]\n",
    "fun_table = fun_doc.tables[2]\n",
    "\n",
    "# fun_cell = fun_table.cells[10]\n",
    "# fun_cell = fun_table.cells[17]\n",
    "fun_cell = fun_table.cells[24]\n",
    "fun_phrase = fun_cell.phrases[0]\n",
    "fun_span = Span(char_start=0, char_end=10, context=fun_phrase)\n",
    "\n",
    "print fun_cell.text, fun_cell.row_num, fun_cell.col_num, fun_table.position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aligned_cells = fun_cell.aligned_cells('row', induced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rs2831617 5 1\n",
      "Cell('17903293', 2, 9, u'Interleukin-6, C-reactive protein and Fibrinogen') 3 0\n",
      "Cell('17903293', 2, 25, u'21') 5 2\n",
      "Cell('17903293', 2, 26, u'28481515') 5 3\n",
      "Cell('17903293', 2, 27, u'6.2*10 -4') 5 4\n",
      "Cell('17903293', 2, 28, u'0.0027') 5 5\n",
      "Cell('17903293', 2, 22, u'IL2RA , RBM17') 4 6\n",
      "[Cell('17903293', 2, 9, u'Interleukin-6, C-reactive protein and Fibrinogen'), Cell('17903293', 2, 25, u'21'), Cell('17903293', 2, 26, u'28481515'), Cell('17903293', 2, 27, u'6.2*10 -4'), Cell('17903293', 2, 28, u'0.0027'), Cell('17903293', 2, 22, u'IL2RA , RBM17')]\n"
     ]
    }
   ],
   "source": [
    "print fun_cell.text, fun_cell.row_num, fun_cell.col_num\n",
    "for cell in aligned_cells:\n",
    "    print cell, cell.row_num, cell.col_num\n",
    "print aligned_cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Learning the correctness of relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a gold set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a gold set, we save all extracted relations into a csv file. We annotate it manually, and save the result to a second file. It contains pairs of phenotype and rsid strings; if that file exists, we take these as gold truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# store relations to annotate\n",
    "with open('candidates.unnanotated.tsv', 'w') as f:\n",
    "    for span_pair in new_candidates:\n",
    "        doc_id = span_pair.span0.context.document.name\n",
    "        table_id = span_pair.span0.context.table.position\n",
    "        row_num = span_pair.span0.context.document.name\n",
    "        str1 = span_pair.span0.get_span()\n",
    "        str2 = span_pair.span1.get_span()\n",
    "        try:\n",
    "            f.write('%s\\t%s\\t%s\\%s\\t%s\\n' % (doc_id, table_id, row_num, str1, str2))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
