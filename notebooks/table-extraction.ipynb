{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting SNP/P-value relations from tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module parses XML tables and extracts relations between SNPs and the p-values at which they are deemed to be significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by configuring Jupyter and setting up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import cPickle\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "\n",
    "# set the paths to snorkel and gwaskb\n",
    "sys.path.append('../snorkel-tables')\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../src/crawler')\n",
    "\n",
    "# set up the directory with the input papers\n",
    "abstract_dir = '../data/db/papers'\n",
    "\n",
    "# set up matplotlib\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (12,4)\n",
    "\n",
    "# create a Snorkel session\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load our usual corpus of GWAS papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import XMLMultiDocParser\n",
    "from extractor.parser import UnicodeXMLTableDocParser\n",
    "\n",
    "xml_parser = XMLMultiDocParser(\n",
    "    path=abstract_dir,\n",
    "    doc='./*',\n",
    "    text='.//table',\n",
    "    id='.//article-id[@pub-id-type=\"pmid\"]/text()',\n",
    "    keep_xml_tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded corpus of 589 documents\n"
     ]
    }
   ],
   "source": [
    "from snorkel.parser import CorpusParser, OmniParser\n",
    "from snorkel.models import Corpus\n",
    "\n",
    "# parses tables into rows, cols, cells...\n",
    "table_parser = OmniParser(timeout=1000000)\n",
    "\n",
    "try:\n",
    "    corpus = session.query(Corpus).filter(Corpus.name == 'GWAS Table Corpus').one()\n",
    "except:\n",
    "    cp = CorpusParser(xml_parser, table_parser)\n",
    "    %time corpus = cp.parse_corpus(name='GWAS Table Corpus', session=session)\n",
    "    session.add(corpus)\n",
    "    session.commit()\n",
    "\n",
    "print 'Loaded corpus of %d documents' % len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining candidate matchers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We genereate RSid candidates from all spans that match the following regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.matchers import RegexMatchSpan\n",
    "rsid_matcher = RegexMatchSpan(rgx=r'rs\\d+(/[ATCG]{1,2})*$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, p-value candidates are all spans that match the following regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import TableNgrams\n",
    "from snorkel.matchers import RegexMatchSpan, Union\n",
    "\n",
    "# 1: p-value matcher\n",
    "\n",
    "rgx1 = u'[1-9]\\d?[\\xb7\\.]?\\d*[\\s\\u2009]*[\\xd7\\xb7\\*][\\s\\u2009]*10[\\s\\u2009]*[-\\u2212\\u2013\\u2012][\\s\\u2009]*\\d+'\n",
    "pval_rgx_matcher1 = RegexMatchSpan(rgx=rgx1)\n",
    "rgx2 = u'[1-9]\\d?[\\xb7\\.]?\\d*[\\s\\u2009]*[eE][\\s\\u2009]*[-\\u2212\\u2013\\u2012][\\s\\u2009]*\\d+'\n",
    "pval_rgx_matcher2 = RegexMatchSpan(rgx=rgx2)\n",
    "rgx3 = u'0\\.0000+\\d+'\n",
    "pval_rgx_matcher3 = RegexMatchSpan(rgx=rgx3)\n",
    "pval_rgx_matcher = Union(pval_rgx_matcher1, pval_rgx_matcher2, pval_rgx_matcher3)\n",
    "\n",
    "# 2: column-based matcher (currently not used)\n",
    "\n",
    "from snorkel.matchers import CellNameRegexMatcher\n",
    "\n",
    "pval_rgx = 'p\\s?.?\\s?value'\n",
    "pval_rgxname_matcher = CellNameRegexMatcher(axis='col', rgx=pval_rgx, n_max=3, ignore_case=True, header_only=True, max_chars=20)\n",
    "\n",
    "# 3: combine the two\n",
    "\n",
    "pval_matcher = Union(pval_rgx_matcher, pval_rgxname_matcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract candidate relations between SNPs and p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a Snorkel class for the relation we will extract\n",
    "from snorkel.models import candidate_subclass\n",
    "RsidPhenRel = candidate_subclass('RsidPvalRel', ['rsid','pval'])\n",
    "\n",
    "# define our candidate spaces\n",
    "from snorkel.candidates import TableNgrams\n",
    "unigrams = TableNgrams(n_max=1)\n",
    "heptagrams = TableNgrams(n_max=7)\n",
    "\n",
    "# we will be looking only at aligned cells\n",
    "from snorkel.throttlers import AlignmentThrottler\n",
    "row_align_filter = AlignmentThrottler(axis='row', infer=False)\n",
    "\n",
    "# the first extractor looks at phenotype names in columns with a header indicating it's a phenotype\n",
    "from snorkel.candidates import CandidateExtractor\n",
    "ce = CandidateExtractor(RsidPhenRel, [unigrams, heptagrams], [rsid_matcher, pval_rgx_matcher], throttler=row_align_filter)\n",
    "\n",
    "# collect that cells that will be searched for candidates\n",
    "tables = [table for doc in corpus.documents for table in doc.tables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22536 relations extracted, e.g.\n",
      "RsidPvalRel(Span(\"rs12722489\", parent=416148, chars=[0,9], words=[0,0]), Span(\"2.16E-07\", parent=416156, chars=[0,7], words=[0,0]))\n",
      "RsidPvalRel(Span(\"rs1736916\", parent=416112, chars=[0,8], words=[0,0]), Span(\"1.22E-07\", parent=416120, chars=[0,7], words=[0,0]))\n",
      "RsidPvalRel(Span(\"rs2857439\", parent=416028, chars=[0,8], words=[0,0]), Span(\"1.86E-10\", parent=416036, chars=[0,7], words=[0,0]))\n",
      "RsidPvalRel(Span(\"rs17421624\", parent=415992, chars=[0,9], words=[0,0]), Span(\"9.72E-15\", parent=416000, chars=[0,7], words=[0,0]))\n",
      "RsidPvalRel(Span(\"rs3094157\", parent=416124, chars=[0,8], words=[0,0]), Span(\"1.24E-07\", parent=416132, chars=[0,7], words=[0,0]))\n",
      "RsidPvalRel(Span(\"rs7382297\", parent=415980, chars=[0,8], words=[0,0]), Span(\"2.01E-15\", parent=415988, chars=[0,7], words=[0,0]))\n",
      "RsidPvalRel(Span(\"rs2647046\", parent=415968, chars=[0,8], words=[0,0]), Span(\"1.43E-17\", parent=415976, chars=[0,7], words=[0,0]))\n",
      "RsidPvalRel(Span(\"rs3905495\", parent=416100, chars=[0,8], words=[0,0]), Span(\"4.76E-08\", parent=416108, chars=[0,7], words=[0,0]))\n",
      "RsidPvalRel(Span(\"rs4959093\", parent=415956, chars=[0,8], words=[0,0]), Span(\"8.18E-34\", parent=415964, chars=[0,7], words=[0,0]))\n",
      "RsidPvalRel(Span(\"rs2517646\", parent=416004, chars=[0,8], words=[0,0]), Span(\"1.95E-11\", parent=416012, chars=[0,7], words=[0,0]))\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "    \n",
    "try:\n",
    "    rels = session.query(CandidateSet).filter(CandidateSet.name == 'RsidPvalRel Relations').one()\n",
    "except:\n",
    "    %time rels = ce.extract(tables, 'RsidPvalRel Relations', session)\n",
    "    session.add(rels)\n",
    "    session.commit()\n",
    "\n",
    "print \"%s relations extracted, e.g.\" % len(rels)\n",
    "for cand in rels[:10]:\n",
    "    print cand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save this for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from extractor.util import pvalue_to_float\n",
    "\n",
    "def clean_rsid(rsid):\n",
    "    return re.sub('/.+', '', rsid)\n",
    "\n",
    "with open('results/nb-output/pval-rsid.tsv', 'w') as f:\n",
    "    for rel in rels:\n",
    "        pmid = rel[0].parent.document.name\n",
    "        table_id = rel[0].parent.table.position\n",
    "        row_id = rel[0].parent.cell.row.position\n",
    "        col_id = rel[0].parent.cell.col.position\n",
    "        rsid = rel[0].get_span()\n",
    "        log_pval = pvalue_to_float(rel[1].get_span())\n",
    "        \n",
    "        try:\n",
    "            out_str = '%s\\t%s\\t%d\\t%d\\t%d\\t%f\\n' % (pmid, clean_rsid(rsid), table_id, row_id, col_id, log_pval)\n",
    "        except:\n",
    "            print 'could not write:', pmid, clean_rsid(rsid), table_id, row_id, col_id, log_pval\n",
    "        f.write(out_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting singleton SNPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There also exist many papers that don't report p-values. To handle these, we also report certain rsids that have *not* been associated with a p-value.\n",
    "\n",
    "Here, we extract these entites. Later on, we will filter them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the extractor\n",
    "from snorkel.models import candidate_subclass\n",
    "from snorkel.matchers import RegexMatchSpan\n",
    "from snorkel.candidates import CandidateExtractor\n",
    "\n",
    "RSID = candidate_subclass('SnorkelRsid 2', ['rsid'])\n",
    "\n",
    "unigrams = TableNgrams(n_max=1)\n",
    "rsid_singleton_matcher = RegexMatchSpan(rgx=r'rs\\d+(/[^s]+)?')\n",
    "rsid_singleton_extractor = CandidateExtractor(RSID, unigrams, rsid_singleton_matcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the extraction process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1648 tables loaded\n",
      "[========================================] 100%\n",
      "CPU times: user 3min 31s, sys: 1min 13s, total: 4min 44s\n",
      "Wall time: 4min 48s\n",
      "15333 candidates extracted\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "\n",
    "try:\n",
    "    rsid_c = session.query(CandidateSet).filter(CandidateSet.name == 'Rsid Candidates 2').one()\n",
    "except:\n",
    "    tables = [table for doc in corpus.documents for table in doc.tables]\n",
    "    print '%d tables loaded' % len(tables)\n",
    "    %time rsid_c = rsid_singleton_extractor.extract(tables, 'Rsid Candidates 2', session)\n",
    "    session.add(rsid_c)\n",
    "    session.commit()\n",
    "\n",
    "print '%d candidates extracted' % len(rsid_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store candidates that occur in sufficiently large tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rsid_by_table = dict()\n",
    "for cand in rsid_c:\n",
    "    rsid = cand[0].get_span()\n",
    "    key = cand[0].parent.document.name, cand[0].parent.table.position\n",
    "    if key not in rsid_by_table: rsid_by_table[key] = set()\n",
    "    rsid_by_table[key].add((rsid, cand[0].parent.cell.row.position, cand[0].parent.cell.col.position))\n",
    "    \n",
    "with open('results/nb-output/rsids.singletons.all.tsv', 'w') as f:\n",
    "    for (pmid, table_id), rsids in rsid_by_table.items():\n",
    "        if len(rsids) < 10: continue\n",
    "        for rsid, row_num, col_num in rsids:\n",
    "            f.write('%s\\t%s\\t%s\\t%s\\t%s\\n' % (pmid, table_id, row_num, col_num, rsid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we store certain table features that will be used to select which singelton rsid's to report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 162 of the file /System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "pval_rgx = 'p\\s?.?\\s?value'\n",
    "lod_rgx = 'LOD'\n",
    "\n",
    "def has_pval(txt):\n",
    "    if re.search(pval_rgx, txt, re.IGNORECASE):\n",
    "        return True\n",
    "    elif txt.lower() == 'p':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "with open('results/nb-output/table-annotations.tsv', 'w') as f:\n",
    "    for doc in corpus.documents:\n",
    "        for table in doc.tables:\n",
    "            lod_found = 0\n",
    "            pval_found = 0\n",
    "            for cell in table.cells:\n",
    "                txt = soup(cell.text).text\n",
    "                if not pval_found and len(txt) < 30 and has_pval(txt):\n",
    "                    pval_found = 1\n",
    "                if not lod_found and re.search(lod_rgx, txt):\n",
    "                    lod_found = 1\n",
    "                if pval_found and lod_found: break\n",
    "                    \n",
    "            out_str = '%s\\t%s\\t%s\\t%s\\n' % (doc.name, table.position, pval_found, lod_found)\n",
    "            f.write(out_str) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we perform a bit of filtering in post-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22536 20258\n"
     ]
    }
   ],
   "source": [
    "rels = []\n",
    "loc2rsid = dict()\n",
    "with open('results/nb-output/pval-rsid.tsv') as f:\n",
    "    for line in f:\n",
    "        pmid, rsid, table_id, row_id, col_id, pval = line.strip().split('\\t')\n",
    "        loc = pmid, table_id, row_id\n",
    "        rels.append((pmid, rsid, table_id, row_id, col_id, pval))\n",
    "        if loc not in loc2rsid: loc2rsid[loc] = set()\n",
    "        loc2rsid[loc].add(rsid)\n",
    "\n",
    "n = 0\n",
    "with open('results/nb-output/pval-rsid.filtered.tsv', 'w') as f:\n",
    "    for rel in rels:\n",
    "        pmid, rsid, table_id, row_id, col_id, pval = rel\n",
    "        loc = pmid, table_id, row_id\n",
    "        if len(loc2rsid[loc]) > 1: continue\n",
    "        \n",
    "        out_str = '%s\\t%s\\t%s\\t%s\\t%s\\t%s\\n' % (pmid, rsid, table_id, row_id, col_id, pval)\n",
    "        f.write(out_str)\n",
    "        n += 1\n",
    "        \n",
    "print len(rels), n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
